{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstrations of Sifter Precalc/SQL Functionality\n",
    "\n",
    " - This notebook contains a mixture of demos of finished code, as well as WIP experimentation with ways to speed-up the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'sifter.sql' from '/home/malexand/.anaconda3/envs/astroconda36/lib/python3.6/site-packages/sifter/sql.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import sys\n",
    "from collections import Counter\n",
    "import glob \n",
    "import warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "from astropy.time import Time\n",
    "\n",
    "# -------------------------------------------------------------------------------------\n",
    "# Local imports\n",
    "# -------------------------------------------------------------------------------------\n",
    "sys.path.append( os.path.join(os.path.dirname(os.getcwd() ), 'tests')  )\n",
    "sys.path.append( os.path.join(os.path.dirname(os.path.dirname(os.getcwd()) ), 'orbit_cheby', 'orbit_cheby')  )\n",
    "from sifter import precalc, sql\n",
    "import orbit_cheby\n",
    "import test_tracklets \n",
    "\n",
    "importlib.reload(orbit_cheby)\n",
    "importlib.reload(precalc)\n",
    "importlib.reload(test_tracklets)\n",
    "importlib.reload(sql)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicit Test Code Exists in sifter/tests\n",
    "\n",
    " - test_sqlite.py\n",
    " - test_tracklets.py\n",
    " \n",
    " Run these using pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Level: \"Tracklets\" - Storage of obs80-strings for multiple tracklets\n",
    " - This takes input sets of obs80-strings (assumed to have already been partitioned into subsets, one subset per tracklet), performs some useful precalculations, and then saves them into an sql database\n",
    " - This calls a number of under-lying functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "####--- Here I set up an empty database and create some fake observations ---###\n",
    "\n",
    "# Create db from scratch (uses convenience funciton from test-suite)\n",
    "test_tracklets.convenience_func_create_db_and_tables()\n",
    "\n",
    "# Read in ITF (or some small part of it)\n",
    "ITF_file = '../dev_data/test.itf'\n",
    "with open(ITF_file) as f:\n",
    "  observation_list = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.32 s, sys: 4 ms, total: 1.33 s\n",
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# instantiate with observation_pair\n",
    "T = precalc.Tracklets(observation_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data uploaded as required\n",
      "CPU times: user 17 ms, sys: 2 ms, total: 19 ms\n",
      "Wall time: 24.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# test that the above caused the tracklet to be uploaded to db\n",
    "cur = T.conn.cursor()\n",
    "cur.execute('SELECT * from tracklets')\n",
    "f = cur.fetchone()\n",
    "assert( len(f)>3 ), 'data not uploaded'\n",
    "if len(f) > 3 : print('Data uploaded as required')\n",
    "\n",
    "# Completely delete db to facilitate future testing\n",
    "os.remove(sql.fetch_db_filepath())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lower-Level Functionalities\n",
    " - The above \"Tracklets\" instantiation uses some underlying functionality to perform the parsing & storage of the obs80 strings\n",
    " - Here we demonstrate some of the underlying functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sql.create_connection\n",
    " - Create a connection to an extant database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46 ms, sys: 0 ns, total: 46 ms\n",
      "Wall time: 47.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Where do we want the db to live\n",
    "assert 'sifter' in sql.fetch_db_filepath()\n",
    "\n",
    "if os.path.isfile( sql.fetch_db_filepath() ):\n",
    "    os.remove(sql.fetch_db_filepath())\n",
    "\n",
    "# Does a db get created & connected-to ?\n",
    "conn = sql.create_connection( sql.fetch_db_filepath() )\n",
    "assert os.path.isfile( os.path.join( sql.fetch_db_filepath() ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### precalc.Tracklets.parse_all_observations\n",
    " - parse a single long list of all observations, splits them into tracklets, performs calculations of (e.g.) HP, RoM, etc, and then creates an summary dictionary for each, and sticking all the dictionaries in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 757 ms, sys: 8 ms, total: 765 ms\n",
      "Wall time: 754 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# define observations\n",
    "# Read in ITF (or some small part of it)\n",
    "ITF_file = '../dev_data/test.itf'\n",
    "with open(ITF_file) as f:\n",
    "  observation_list = f.readlines()    \n",
    "\n",
    "# call parse_all_observations\n",
    "tracklet_dictionary_list = T.parse_all_observations(observation_list)\n",
    "\n",
    "\n",
    "# check that the returned results are as expected\n",
    "assert isinstance(tracklet_dictionary_list, list)\n",
    "for tracklet_dictionary in tracklet_dictionary_list:\n",
    "    assert 'JD' in tracklet_dictionary\n",
    "    assert 'HP' in tracklet_dictionary\n",
    "    assert 'tracklet_name' in tracklet_dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### precalc.Tracklets.parse_tracklet_observations\n",
    " - parse the list of observations for a single tracklet, perform calculations of (e.g.) HP, RoM, etc, and then creates an summary dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 ms, sys: 0 ns, total: 13 ms\n",
      "Wall time: 13.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# define observations\n",
    "tracklet_observations= [ '     K11Q88F*~C2011 08 29.52378 01 57 34.729+14 35 44.64         22.8 rc~0qBd568',\n",
    "                         '     K11Q88F ~C2011 08 29.55470 01 57 34.343+14 35 42.61         22.9 rc~0qBd568',\n",
    "                         '     K11Q88F ~C2011 08 29.61470 01 57 34.343+14 35 42.59         22.9 rc~0qBd568']\n",
    "    \n",
    "# call parse_observations\n",
    "tracklet_dictionary = T.parse_tracklet_observations(tracklet_observations)\n",
    "\n",
    "\n",
    "# check that the returned results are as expected\n",
    "assert isinstance(tracklet_dictionary, dict)\n",
    "assert 'JD' in tracklet_dictionary\n",
    "assert 'HP' in tracklet_dictionary\n",
    "assert 'tracklet_name' in tracklet_dictionary\n",
    "assert 'observations' in tracklet_dictionary\n",
    "assert tracklet_observations == tracklet_dictionary['observations']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### precalc.identify_tracklets\n",
    " - This function takes a long list of observations and identifies tracklets, sticking them together into a list containing a list of observation for each tracklet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 1 ms, total: 1 ms\n",
      "Wall time: 245 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Define some observations\n",
    "# Here we have three dummy triplets, with the last two intentionally using the same trksub\n",
    "# in order to test that identify_tracklets correctly identifies them as separate tracklets. \n",
    "observation_list= ['     K11Q88F*~C2011 08 29.52378 01 57 34.729+14 35 44.64         22.8 rc~0qBd568',\n",
    "                   '     K11Q88F ~C2011 08 29.55470 01 57 34.343+14 35 42.61         22.9 rc~0qBd568',\n",
    "                   '     K11Q88F ~C2011 08 29.61470 01 57 34.343+14 35 42.59         22.9 rc~0qBd568',\n",
    "                   '     K11Q99F*~C2012 08 29.52378 01 57 34.729+14 35 44.64         22.8 rc~0qBd568',\n",
    "                   '     K11Q99F ~C2012 08 29.58470 01 57 34.343+14 35 42.61         22.9 rc~0qBd568',\n",
    "                   '     K11Q99F ~C2012 08 29.61470 01 57 34.343+14 35 42.59         22.9 rc~0qBd568',\n",
    "                   '     K11Q99F ~C2018 09 28.52378 01 57 34.729+14 35 44.64         22.8 rc~0qBd568',\n",
    "                   '     K11Q99F ~C2018 09 28.58470 01 57 34.343+14 35 42.61         22.9 rc~0qBd568',\n",
    "                   '     K11Q99F ~C2018 09 28.61470 01 57 34.343+14 35 42.59         22.9 rc~0qBd568',\n",
    "                   ]\n",
    "# Split into tracklet lists using identify_tracklets:\n",
    "list_of_lists = precalc.identify_tracklets(observation_list)\n",
    "# Check that there are three tracklets as expected:\n",
    "assert len(list_of_lists) == 3\n",
    "assert len(list_of_lists[0]) == 3\n",
    "assert len(list_of_lists[1]) == 3\n",
    "assert len(list_of_lists[2]) == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### precalc.save_tracklets & sql.upsert_tracklets\n",
    " - Saves a dictionary into a SQLITE db, using JD & HP as important columns for selection/query later-on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 91 ms, sys: 4 ms, total: 95 ms\n",
      "Wall time: 135 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# Create db from scratch\n",
    "test_tracklets.convenience_func_create_db_and_tables()\n",
    "\n",
    "\n",
    "# Set up a Tracklet and use the parse_observations routine to get JD, HP, ...\n",
    "T = precalc.Tracklets()\n",
    "observation_pairs= [[ '     K11Q88F*~C2011 08 29.52378 01 57 34.729+14 35 44.64         22.8 rc~0qBd568',\n",
    "                     '     K11Q88F ~C2011 08 29.55470 01 57 34.343+14 35 42.61         22.9 rc~0qBd568',\n",
    "                     '     K11Q88F ~C2011 08 29.61470 01 57 34.343+14 35 42.59         22.9 rc~0qBd568'],\n",
    "                    [ '     K11Q99F*~C2012 08 29.52378 01 57 34.729+14 35 44.64         22.8 rc~0qBd568',\n",
    "                     '     K11Q99F ~C2012 08 29.58470 01 57 34.343+14 35 42.61         22.9 rc~0qBd568',\n",
    "                     '     K11Q99F ~C2012 08 29.61470 01 57 34.343+14 35 42.59         22.9 rc~0qBd568']]\n",
    "    \n",
    "# call parse_tracklet_observations\n",
    "tracklet_dictionary_list = [T.parse_tracklet_observations(tracklet_observations) for tracklet_observations in observation_pairs]\n",
    "\n",
    "# Now save the data in the db\n",
    "T.save_tracklets(tracklet_dictionary_list)\n",
    "\n",
    "# Test the data was uploaded and can be downloaded\n",
    "cur = T.conn.cursor()\n",
    "cur.execute('SELECT * from tracklets')\n",
    "f = cur.fetchall()\n",
    "assert( len(f)==2 and np.all([ len(_)>3 for _ in f]) ), 'data not uploaded'\n",
    "\n",
    "# Completely delete db to facilitate future testing\n",
    "os.remove(sql.fetch_db_filepath())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
